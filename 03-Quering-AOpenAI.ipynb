{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d59d527f-1100-45ff-b051-5f7c9029d94d",
   "metadata": {},
   "source": [
    "# Queries with and without Azure OpenAI"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb9a9444-dc90-4fc3-aea7-8ee918301aba",
   "metadata": {},
   "source": [
    "Now that we have our Search Engine loaded **from two different data sources in two diferent indexes**, we are going to try some example queries and then use Azure OpenAI service to see if we can get even better results.\n",
    "\n",
    "The idea is that a user can ask a question about Computer Science (first datasource/index) or about Covid (second datasource/index), and the engine will respond accordingly.\n",
    "This **Multi-Index** demo, mimics the scenario where a company loads multiple type of documents of different types and about completly different topics and the search engine must respond with the most relevant results."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71f6c7e3-9037-4b1e-ae17-1deaa27b9c08",
   "metadata": {},
   "source": [
    "## Set up variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8e50b404-a061-49e7-a3c7-c6eabc98ff0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import urllib\n",
    "import requests\n",
    "import random\n",
    "from collections import OrderedDict\n",
    "from IPython.display import display, HTML\n",
    "from langchain.llms import AzureOpenAI\n",
    "from langchain.chat_models import AzureChatOpenAI\n",
    "from langchain.vectorstores import FAISS\n",
    "from langchain.docstore.document import Document\n",
    "from langchain.chains.question_answering import load_qa_chain\n",
    "from langchain.chains.qa_with_sources import load_qa_with_sources_chain\n",
    "from langchain.embeddings import HuggingFaceEmbeddings\n",
    "\n",
    "from app.embeddings import OpenAIEmbeddings\n",
    "from app.prompts import STUFF_PROMPT, REFINE_PROMPT, REFINE_QUESTION_PROMPT\n",
    "\n",
    "# Demo Datasource Blob Storage. Change if using your own data\n",
    "DATASOURCE_SAS_TOKEN = \"?sv=2021-12-02&ss=b&srt=sco&sp=rltfx&se=2024-04-05T09:10:04Z&st=2023-04-05T01:10:04Z&spr=https&sig=Rm52BKJs%2BziCnKSmCHdWsQqVki4FsMuiH25MsZAN7Z8%3D\"\n",
    "\n",
    "# Don't mess with this unless you really know what you are doing\n",
    "AZURE_SEARCH_API_VERSION = '2021-04-30-Preview'\n",
    "AZURE_OPENAI_API_VERSION = \"2023-03-15-preview\"\n",
    "\n",
    "# Change these below with your own services credentials\n",
    "AZURE_SEARCH_ENDPOINT = \"Enter your Azure Cognitive Search Endpoint ...\"\n",
    "AZURE_SEARCH_KEY = \"Enter your Azure Cognitive Search Key ...\"\n",
    "AZURE_OPENAI_ENDPOINT = \"Enter your Azure OpenAI Endpoint ...\"\n",
    "AZURE_OPENAI_API_KEY = \"Enter your Azure OpenAI Key ...\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2f2c22f8-79ab-405c-95e8-77a1978e53bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setup the Payloads header\n",
    "headers = {'Content-Type': 'application/json','api-key': AZURE_SEARCH_KEY}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9297d29b-1f61-4dce-858e-bf4272172dba",
   "metadata": {},
   "source": [
    "## Multi-Index Search queries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5a46e2d3-298a-4708-83de-9e108b1a117a",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Index that we are going to query (from Notebook 01 and 02)\n",
    "index1_name = \"cogsrch-index-files\"\n",
    "index2_name = \"cogsrch-index-csv\"\n",
    "indexes = [index1_name, index2_name]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c62ebb2-d7be-4bfb-b1ba-4db86c11839a",
   "metadata": {},
   "source": [
    "Try questions that you think might be answered or addressed in computer science papers in 2020-2021 or that can be addressed by medical publications about COVID in 2020. Try comparing the results with the open version of ChatGPT.<br>\n",
    "The idea is that the answers using Azure OpenAI only looks at the information contained on these publications.\n",
    "\n",
    "**Example Questions you can ask**:\n",
    "- What is CLP?\n",
    "- How Markov chains work?\n",
    "- What are some examples of reinforcement learning?\n",
    "- What are the main risk factors for Covid-19?\n",
    "- What medicine reduces inflamation in the lungs?\n",
    "- Why Covid doesn't affect kids that much compared to adults?\n",
    "- Does chloroquine really works against covid?\n",
    "- tell me Use cases where I can use deep learning to solve it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "b9b53c14-19bd-451f-aa43-7ad27ccfeead",
   "metadata": {},
   "outputs": [],
   "source": [
    "QUESTION = \"What is CLP?\" \n",
    "# This questions is interesting since CLP means something in Computer science and means something different in medical field "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6d925eb-7f9c-429e-a62a-4c37d7702caf",
   "metadata": {},
   "source": [
    "### Search on both indexes individually and aggragate results\n",
    "\n",
    "Note: In order to standarize the indexes we are setting 4 mandatory fields to be present on each index: id, title, content, pages, language. These fields must be present in each index so that each document can be treated the same along the code."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "faf2e30f-e71f-4533-ab52-27d048b80a89",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "https://azure-cog-search-cstevuxaqrxcm.search.windows.net/indexes/cogsrch-index-files/docs?api-version=2021-04-30-Preview&search=What is CLP?&select=*&$top=5&queryLanguage=en-us&queryType=semantic&semanticConfiguration=my-semantic-config&$count=true&speller=lexicon&answers=extractive|count-3&captions=extractive|highlight-false\n",
      "200\n",
      "Results Found: 9789, Results Returned: 5\n",
      "https://azure-cog-search-cstevuxaqrxcm.search.windows.net/indexes/cogsrch-index-csv/docs?api-version=2021-04-30-Preview&search=What is CLP?&select=*&$top=5&queryLanguage=en-us&queryType=semantic&semanticConfiguration=my-semantic-config&$count=true&speller=lexicon&answers=extractive|count-3&captions=extractive|highlight-false\n",
      "200\n",
      "Results Found: 22435, Results Returned: 5\n"
     ]
    }
   ],
   "source": [
    "agg_search_results = []\n",
    "\n",
    "for index in indexes:\n",
    "    url = AZURE_SEARCH_ENDPOINT + '/indexes/'+ index + '/docs'\n",
    "    url += '?api-version={}'.format(AZURE_SEARCH_API_VERSION)\n",
    "    url += '&search={}'.format(QUESTION)\n",
    "    url += '&select=*'\n",
    "    url += '&$top=5'  # You can change this to anything you need/want\n",
    "    url += '&queryLanguage=en-us'\n",
    "    url += '&queryType=semantic'\n",
    "    url += '&semanticConfiguration=my-semantic-config'\n",
    "    url += '&$count=true'\n",
    "    url += '&speller=lexicon'\n",
    "    url += '&answers=extractive|count-3'\n",
    "    url += '&captions=extractive|highlight-false'\n",
    "\n",
    "    resp = requests.get(url, headers=headers)\n",
    "    print(url)\n",
    "    print(resp.status_code)\n",
    "\n",
    "    search_results = resp.json()\n",
    "    agg_search_results.append(search_results)\n",
    "    print(\"Results Found: {}, Results Returned: {}\".format(search_results['@odata.count'], len(search_results['value'])))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7fd0fe5-4ee0-42e2-a920-72b93a407389",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Display the top results (from both searches) based on the score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "9e938337-602d-4b61-8141-b8c92a5d91da",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<h4>Top Answers</h4>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<h5>Answer - score: 0.99</h5>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Constraint Logic Programming (CLP) is an emerging software technology with a growing number of applications. Data flow in constraint programs is not explicit, and for this reason the concepts of slice and the slicing techniques of imperative languages are not directly applicable. This paper formulates declarative notions of slice suitable for CLP."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<h5>Answer - score: 0.97</h5>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "The key notions of CLP are those of an algebra and an associated constraint solver over a class of constraints, namely a set of first order formulas including the always satisfiable constraint true, the un- satisfiable constraint false, and closed under variable renaming, conjunction and existential quantification."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<h5>Answer - score: 0.92</h5>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "A solution is an instantiation of the variables of X which satisfies all the constraints in R.  2.1 Constraint Logic Programming  Constraint logic programming (CLP) [7] is an extension of logic programming where some of the predicate and function symbols have a fixed interpretation over some subdomain (e.g. finite trees or real numbers)."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<h4>Top Results</h4>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<h5><a href=\"https://demodatasetsp.blob.core.windows.net/arxivcs/0008/0008036v1.pdf?sv=2021-12-02&ss=b&srt=sco&sp=rltfx&se=2024-04-05T09:10:04Z&st=2023-04-05T01:10:04Z&spr=https&sig=Rm52BKJs%2BziCnKSmCHdWsQqVki4FsMuiH25MsZAN7Z8%3D\">arXiv:cs/0008036v1  [cs.CL]  30 Aug 2000</a> - score: 2.04</h5>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "To this end,  we discuss the formal basics of Constraint Logic Programming (CLP), which is used here  to provide an operational treatment of various declarative constraint-based grammars. This  is done by an embedding of the logical description languages of such grammars into a CLP  scheme, yielding Constraint Logic Grammars (CLGs)."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<h5><a href=\"https://demodatasetsp.blob.core.windows.net/arxivcs/0701/0701082v1.pdf?sv=2021-12-02&ss=b&srt=sco&sp=rltfx&se=2024-04-05T09:10:04Z&st=2023-04-05T01:10:04Z&spr=https&sig=Rm52BKJs%2BziCnKSmCHdWsQqVki4FsMuiH25MsZAN7Z8%3D\">0701082v1.pdf</a> - score: 1.94</h5>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "The key notions of CLP are those of an algebra and an associated constraint solver over a class of constraints, namely a set of first order formulas including the always satisfiable constraint true, the un- satisfiable constraint false, and closed under variable renaming, conjunction and existential quantification."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<h5><a href=\"https://demodatasetsp.blob.core.windows.net/arxivcs/0012/0012014v1.pdf?sv=2021-12-02&ss=b&srt=sco&sp=rltfx&se=2024-04-05T09:10:04Z&st=2023-04-05T01:10:04Z&spr=https&sig=Rm52BKJs%2BziCnKSmCHdWsQqVki4FsMuiH25MsZAN7Z8%3D\">arXiv:cs/0012014v1  [cs.SE]  18 Dec 2000</a> - score: 1.89</h5>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Constraint Logic Programming (CLP) is an emerging software technology with a growing number of applications. Data flow in constraint programs is not explicit, and for this reason the concepts of slice and the slicing techniques of imperative languages are not directly applicable. This paper formulates declarative notions of slice suitable for CLP."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<h5><a href=\"https://demodatasetsp.blob.core.windows.net/arxivcs/0011/0011030v1.pdf?sv=2021-12-02&ss=b&srt=sco&sp=rltfx&se=2024-04-05T09:10:04Z&st=2023-04-05T01:10:04Z&spr=https&sig=Rm52BKJs%2BziCnKSmCHdWsQqVki4FsMuiH25MsZAN7Z8%3D\">arXiv:cs/0011030v1  [cs.AI]  21 Nov 2000</a> - score: 1.66</h5>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "A solution is an instantiation of the variables of X which satisfies all the constraints in R.  2.1 Constraint Logic Programming  Constraint logic programming (CLP) [7] is an extension of logic programming where some of the predicate and function symbols have a fixed interpretation over some subdomain (e.g. finite trees or real numbers)."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<h5><a href=\"https://demodatasetsp.blob.core.windows.net/arxivcs/0408/0408056v1.pdf?sv=2021-12-02&ss=b&srt=sco&sp=rltfx&se=2024-04-05T09:10:04Z&st=2023-04-05T01:10:04Z&spr=https&sig=Rm52BKJs%2BziCnKSmCHdWsQqVki4FsMuiH25MsZAN7Z8%3D\">0408056v1.pdf</a> - score: 1.62</h5>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "CLP(FD) languages have been suc-  cessfully used for solving a variety of industrial and academic problems. However,  in some constraint problems, where domain elements need to be acquired, it may  not be wise to perform the acquisition of the whole domains of variables before the  beginning of the constraint propagation process."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<h5><a href=\"https://demodatasetsp.blob.core.windows.net/litcovid/train.csv?sv=2021-12-02&ss=b&srt=sco&sp=rltfx&se=2024-04-05T09:10:04Z&st=2023-04-05T01:10:04Z&spr=https&sig=Rm52BKJs%2BziCnKSmCHdWsQqVki4FsMuiH25MsZAN7Z8%3D\">Lock-down logistics in Consultation-Liaison Psychiatry.</a> - score: 1.34</h5>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "We describe the adaptation of services to allow flexible and practical responses to the COVID-19 public health crisis by four Consultation-Liaison psychiatry (CLP) services; Galway University Hospital, Beaumont Hospital, University Hospital Waterford and St Vincent's University Hospital CLP Services."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<h5><a href=\"https://demodatasetsp.blob.core.windows.net/litcovid/train.csv?sv=2021-12-02&ss=b&srt=sco&sp=rltfx&se=2024-04-05T09:10:04Z&st=2023-04-05T01:10:04Z&spr=https&sig=Rm52BKJs%2BziCnKSmCHdWsQqVki4FsMuiH25MsZAN7Z8%3D\">Effect of Thymoquinone on Acute Kidney Injury Induced by Sepsis in BALB/c Mice.</a> - score: 1.3</h5>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "CLP was performed after 2 weeks of TQ gavage. After 48 h, we measured the histopathological alterations in the kidney tissue and the serum levels of creatinine (CRE) and blood urea nitrogen (BUN)."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<h5><a href=\"https://demodatasetsp.blob.core.windows.net/litcovid/train.csv?sv=2021-12-02&ss=b&srt=sco&sp=rltfx&se=2024-04-05T09:10:04Z&st=2023-04-05T01:10:04Z&spr=https&sig=Rm52BKJs%2BziCnKSmCHdWsQqVki4FsMuiH25MsZAN7Z8%3D\">Consultation-Liaison Psychiatry During COVID-19 Lockdown: A Retrospective Chart Review.</a> - score: 1.24</h5>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "A retrospective chart review of consultation-liaison psychiatry (CLP) case records was conducted for one month before and after the start of lockdown. Patients seen during lockdown were relatively younger; t = 1.8, p = 0.074."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(HTML('<h4>Top Answers</h4>'))\n",
    "\n",
    "for search_results in agg_search_results:\n",
    "    for result in search_results['@search.answers']:\n",
    "        if result['score'] > 0.5: # Show answers that are at least 50% of the max possible score=1\n",
    "            display(HTML('<h5>' + 'Answer - score: ' + str(round(result['score'],2)) + '</h5>'))\n",
    "            display(HTML(result['text']))\n",
    "            \n",
    "print(\"\\n\\n\")\n",
    "display(HTML('<h4>Top Results</h4>'))\n",
    "\n",
    "file_content = OrderedDict()\n",
    "content = dict()\n",
    "\n",
    "for search_results in agg_search_results:\n",
    "    for result in search_results['value']:\n",
    "        if result['@search.rerankerScore'] > 1: # Filter results that are at least 25% of the max possible score=4\n",
    "            content[result['id']]={\n",
    "                                    \"title\": result['title'],\n",
    "                                    \"chunks\": result['pages'],\n",
    "                                    \"language\": result['language'], \n",
    "                                    \"caption\": result['@search.captions'][0]['text'],\n",
    "                                    \"score\": result['@search.rerankerScore'],\n",
    "                                    \"name\": result['metadata_storage_name'], \n",
    "                                    \"location\": result['metadata_storage_path']                  \n",
    "                                }\n",
    "    \n",
    "#After results have been filtered we will Sort and add them as an Ordered list\\n\",\n",
    "for id in sorted(content, key= lambda x: content[x][\"score\"], reverse=True):\n",
    "    file_content[id] = content[id]\n",
    "    url = file_content[id]['location'] + DATASOURCE_SAS_TOKEN\n",
    "    title = str(file_content[id]['title']) if (file_content[id]['title']) else file_content[id]['name']\n",
    "    score = str(round(file_content[id]['score'],2))\n",
    "    display(HTML('<h5><a href=\"'+ url + '\">' + title + '</a> - score: '+ score + '</h5>'))\n",
    "    display(HTML(file_content[id]['caption']))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52a6d3e6-afb2-4fa7-96d3-69bc2373ded5",
   "metadata": {},
   "source": [
    "## Comments on Query results"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84e02227-6a92-4944-86f8-6c1e38d90fe4",
   "metadata": {},
   "source": [
    "As seen above the semantic search feature of Azure Cognitive Search service is good. It gives us some answers and also the top results with the corresponding file and the paragraph where the answers is possible located.\n",
    "\n",
    "Let's see if we can make this better with Azure OpenAI"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8df3e6d4-9a09-4b0f-b328-238738ccfaec",
   "metadata": {},
   "source": [
    "# Using Azure OpenAI\n",
    "\n",
    "Of course we want OpenAI to give a better answer, so we instead of sending these results, we send the content of the documents of the search result articles to OpenAI and lets GPT model give the answer.\n",
    "\n",
    "The problem is that the content of the search result files is or can be very lengthy, more than the allowed tokens allowed by the GPT Azure OpenAI models. So what we need to do is to split in chunks, vectorize and do a vector semantic search. \n",
    "\n",
    "Notice that **the documents chunks are already done in Azure Search**. file_content dictionary (created in the cell above) contains the pages (chunks) of each document. So we dont really need to chunk them again, each doc page for sure will fit on the max tokens limit of the completions LLM and of the embedding LLM.\n",
    "\n",
    "We will use a genius library call LangChain that wraps a lot of boiler plate code."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "eea62a7d-7e0e-4a93-a89c-20c96560c665",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set the ENV variables that Langchain needs to connect to Azure OpenAI\n",
    "os.environ[\"OPENAI_API_BASE\"] = os.environ[\"AZURE_OPENAI_ENDPOINT\"] = AZURE_OPENAI_ENDPOINT\n",
    "os.environ[\"OPENAI_API_KEY\"] = os.environ[\"AZURE_OPENAI_API_KEY\"] = AZURE_OPENAI_API_KEY\n",
    "os.environ[\"OPENAI_API_VERSION\"] = os.environ[\"AZURE_OPENAI_API_VERSION\"] = AZURE_OPENAI_API_VERSION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "8f7b41d2-65b0-4058-8a46-c76cf6960720",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of chunks: 104\n"
     ]
    }
   ],
   "source": [
    "docs = []\n",
    "for key,value in file_content.items():\n",
    "    for page in value[\"chunks\"]:\n",
    "        docs.append(Document(page_content=page, metadata={\"source\": value[\"location\"]}))\n",
    "        \n",
    "print(\"Number of chunks:\",len(docs))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5403dee-a4c4-420c-9819-68151d973695",
   "metadata": {},
   "source": [
    "Depending of the amount of chunks/pages returned from the search result, which is very related to the size of the documents returned\n",
    "we pick the embedding model that give us fast results. <br>The logic is, if there is less than 50 chunks (of 5000 chars each) to vectorize then we use \n",
    "OpenAI models which currently don't offer batch processing, but if there is more than 50 chunks we use a BERT based in-memory model that processes in batches and in parallel (it is recommended a VM of at least 4 cores).\n",
    "\n",
    "For more information on in-memory models that you can use, see [HERE](https://www.sbert.net/docs/pretrained_models.html)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "a03f1f10-32b0-4c1e-8a0e-eee1b1d29ce7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select the Embedder model\n",
    "if len(docs) < 50:\n",
    "    # OpenAI models are accurate but slower\n",
    "    embedder = OpenAIEmbeddings(document_model_name=\"text-embedding-ada-002\", query_model_name=\"text-embedding-ada-002\") \n",
    "else:\n",
    "    # Bert based models are faster (3x-10x) but not as great in accuracy as OpenAI models\n",
    "    # Since this repo supports Multiple languages we need to use a multilingual model. \n",
    "    # But if English only is the requirement, use \"multi-qa-MiniLM-L6-cos-v1\"\n",
    "    # The fastest english model is \"all-MiniLM-L12-v2\"\n",
    "    if random.choice(list(file_content.items()))[1][\"language\"] == \"en\":\n",
    "        embedder = HuggingFaceEmbeddings(model_name = 'multi-qa-MiniLM-L6-cos-v1')\n",
    "    else:\n",
    "        embedder = HuggingFaceEmbeddings(model_name = 'distiluse-base-multilingual-cased-v2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "a5cc7ae5-6fe9-4fd8-992d-0507297387ea",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "HuggingFaceEmbeddings(client=SentenceTransformer(\n",
       "  (0): Transformer({'max_seq_length': 512, 'do_lower_case': False}) with Transformer model: BertModel \n",
       "  (1): Pooling({'word_embedding_dimension': 384, 'pooling_mode_cls_token': False, 'pooling_mode_mean_tokens': True, 'pooling_mode_max_tokens': False, 'pooling_mode_mean_sqrt_len_tokens': False})\n",
       "  (2): Normalize()\n",
       "), model_name='multi-qa-MiniLM-L6-cos-v1', cache_folder=None)"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embedder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "3315033a-4a08-4db5-8f5c-fa0a99892dc4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 34.8 s, sys: 11.2 s, total: 46 s\n",
      "Wall time: 12 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "if(len(docs)>1):\n",
    "    db = FAISS.from_documents(docs, embedder)\n",
    "else:\n",
    "    print(\"No results Found\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "57429335-34d3-458a-b7c9-52482a0936d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "docs_db = db.similarity_search(QUESTION, k=4)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17247488-7d14-4178-9add-31eb1afcbcbe",
   "metadata": {},
   "source": [
    "At this point we already have the most similar chunks (in order of relevance given by the in-memory vector cosine similarity search) in docs_db"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "793c4788-715e-44dd-b2b8-3f1c3201e4e0",
   "metadata": {},
   "source": [
    "### Now we use GPT-3.5(Turbo) using map-reduce chain in order to stay within the limits of the allow model's token count\n",
    "\n",
    "for more information on the different types of prompts for these chains please see here:\n",
    "\n",
    "https://github.com/hwchase17/langchain/tree/master/langchain/chains/question_answering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "634f5bd8-0d56-47b8-84fd-fe9b678bfc32",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make sure you have the deployment named \"gpt-35-turbo\" for the model \"gpt-35-turbo (0301)\". \n",
    "# Use \"gpt-4\" if you have it available.\n",
    "llm = AzureChatOpenAI(deployment_name=\"gpt-35-turbo\", temperature=0.5, max_tokens=500)\n",
    "chain = load_qa_with_sources_chain(llm, chain_type=\"map_reduce\", return_intermediate_steps=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "a1e619b8-1dcf-431b-8aad-f1696a09c2ac",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 30.9 ms, sys: 1.65 ms, total: 32.6 ms\n",
      "Wall time: 9.96 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "response = chain({\"input_documents\": docs_db, \"question\": QUESTION}, return_only_outputs=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "8cddb1cb-a4a0-4e2f-9f0c-4216b0f232b2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<h4>Azure OpenAI ChatGPT Answer:</h4>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "CLP can refer to different things depending on the context: Consultation-Liaison psychiatry services, constraint logic programming, or finite domain CLP as a tool for Constraint Satisfaction Problem solving. \n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<u>Sources</u>: <sup><a href=\"https://demodatasetsp.blob.core.windows.net/litcovid/train.csv?sv=2021-12-02&ss=b&srt=sco&sp=rltfx&se=2024-04-05T09:10:04Z&st=2023-04-05T01:10:04Z&spr=https&sig=Rm52BKJs%2BziCnKSmCHdWsQqVki4FsMuiH25MsZAN7Z8%3D\">[1]</a></sup><sup><a href=\"https://demodatasetsp.blob.core.windows.net/arxivcs/0008/0008036v1.pdf?sv=2021-12-02&ss=b&srt=sco&sp=rltfx&se=2024-04-05T09:10:04Z&st=2023-04-05T01:10:04Z&spr=https&sig=Rm52BKJs%2BziCnKSmCHdWsQqVki4FsMuiH25MsZAN7Z8%3D\">[2]</a></sup><sup><a href=\"https://demodatasetsp.blob.core.windows.net/arxivcs/0011/0011030v1.pdf?sv=2021-12-02&ss=b&srt=sco&sp=rltfx&se=2024-04-05T09:10:04Z&st=2023-04-05T01:10:04Z&spr=https&sig=Rm52BKJs%2BziCnKSmCHdWsQqVki4FsMuiH25MsZAN7Z8%3D\">[3]</a></sup><sup><a href=\"https://demodatasetsp.blob.core.windows.net/arxivcs/0012/0012014v1.pdf?sv=2021-12-02&ss=b&srt=sco&sp=rltfx&se=2024-04-05T09:10:04Z&st=2023-04-05T01:10:04Z&spr=https&sig=Rm52BKJs%2BziCnKSmCHdWsQqVki4FsMuiH25MsZAN7Z8%3D\">[4]</a></sup>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "answer = response['output_text']\n",
    "\n",
    "display(HTML('<h4>Azure OpenAI ChatGPT Answer:</h4>'))\n",
    "display(HTML(answer.split(\"SOURCES:\")[0]))\n",
    "\n",
    "sources_list = answer.split(\"SOURCES:\")[1].replace(\" \",\"\").split(\",\")\n",
    "\n",
    "sources_html = '<u>Sources</u>: '\n",
    "for index, value in enumerate(sources_list):\n",
    "    url = value + DATASOURCE_SAS_TOKEN\n",
    "    sources_html +='<sup><a href=\"'+ url + '\">[' + str(index+1) + ']</a></sup>'\n",
    "    \n",
    "display(HTML(sources_html))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "11345374-6420-4b36-b061-795d2a804c85",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Uncomment if you want to inspect the results from each top similar chunk summary (k=4 by default)\n",
    "# response['intermediate_steps']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f347373a-a5be-473d-b64e-0f6b6dbcd0e0",
   "metadata": {},
   "source": [
    "# Summary\n",
    "##### This answer is way better than taking just the result from Azure Cognitive Search. So the summary is:\n",
    "- Azure Cognitive Search give us the top results (context)\n",
    "- Azure OpenAI takes these results and understand the content and uses it as context to give the best answer\n",
    "- Best of two worlds!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fdc6e2fe-1c34-4952-99ad-14940f022379",
   "metadata": {},
   "source": [
    "# NEXT\n",
    "We know now how to do a Smart Search Engine!! great!\n",
    "\n",
    "But, does this solve all the possible scenarios that a virtual assistant will require?  **What about if the answer to the Smart Search Engine is not related to text, but instead requires to look into tabular data?** The next notebook 04 explains and solves this problem"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10 - SDK v2",
   "language": "python",
   "name": "python310-sdkv2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
